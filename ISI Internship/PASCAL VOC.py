# -*- coding: utf-8 -*-
"""VGG16Pascal(& steel dataset).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12w447t2RMCHQzEKL04vRnR9cCUeJSTYz
"""

import os
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use("ggplot")
#%matplotlib inline

from tqdm import tqdm_notebook, tnrange
from itertools import chain
from skimage.io import imread, imshow, concatenate_images
from skimage.transform import resize
from skimage.morphology import label
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

import tensorflow as tf
import keras
from keras.models import Model, load_model
from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout
from keras.layers.core import Lambda, RepeatVector, Reshape
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D
from keras.layers.merge import concatenate, add
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
import cv2
from google.colab.patches import cv2_imshow

#mounting google drive to load data
from google.colab import drive
drive.mount('/content/gdrive')

# parameters(VGG16)
im_width = 224
im_height = 224
border = 5

# parameters(UNET)
im_width1 = 128
im_height1 = 128
border = 5

#for creating array consisting name of images
#Use this if a text file containing the images is present. If not, Use ids = os.listdir (Present in loading the training data)
def file_read(fname):
        content_array = []
        content_array_1 = []
        with open(fname) as f:
                #Content_list is the list that contains the read lines.     
                
                for line in f:
                        if line.endswith('\n'):
                            line = line[:-1]
                            content_array.append(line + ".jpg")
                            content_array_1.append(line)
        return content_array, content_array_1


ids,ids_1 = file_read('/content/gdrive/My Drive/Colab Notebooks/Pascal VOC 12/trainval.txt') #file containing the names of images
print(ids)

#for loading the ground truth
def get_mask(id_1):
    masks = np.zeros((6,im_height, im_width,1), dtype=np.float32)
    for i in range(1,7):
      mask = load_img("/content/gdrive/My Drive/Colab Notebooks/Pascal VOC 12/Segmentation_MaskB/"+id_1+str(i)+".png",grayscale=True) #folder containing the masks
      masks[i-1] = img_to_array(mask)
    return masks

# LOADING TRAINING DATA
#ids = os.listdir('/content/gdrive/My Drive/Colab Notebooks/images') # list of names all images in the given path
X = np.zeros((len(ids), im_height, im_width,1), dtype=np.float32)
y = np.zeros((len(ids_1), im_height, im_width,6), dtype=np.int8)

# tqdm is used to display the progress bar
for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):
    # Load images
    img = load_img("/content/gdrive/My Drive/Colab Notebooks/Pascal VOC 12/Final/"+id_,grayscale=True) #folder containing the training images
    x_img = img_to_array(img)
    
    # Save images
    X[n] = x_img/255.0
    
for n_1, id_1 in tqdm_notebook(enumerate(ids_1), total=len(ids_1)):
    # Load masks
    mask = get_mask(id_1)
    mask = np.reshape(mask,(6,224,224))
    mask = mask.transpose((1, 2, 0))

    # Save masks
    y[n_1] = mask/255.0

print(X.shape,y.shape)

# splitting the training data set and erasing the original training array
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)
X = []
y = []

#counting number of images in each class
c = 0
for i in range(0,len(y_train)):
  if(np.count_nonzero(y_train[i,:,:,5])>0):
    c = c + 1
print(c)

cv2_imshow(X_train[0,:,:,0]*255)
cv2_imshow(y_train[0,:,:,0]*255)

#Visualisation of training data images and mask
#ix = random.randint(0, len(X_train))
ix = 13
iy = 3
has_mask = y_train[ix].max() > 0 # salt indicator

fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 15))

ax1.imshow(X_train[ix, ..., 0])
if has_mask: # if salt draw a boundary(contour) in the original image separating salt and non-salt areas
    ax1.contour(y_train[ix,:,:,0].squeeze(), colors = 'k', linewidths = 5, levels = [0.5])
ax1.set_title('Actual')

ax2.imshow(y_train[ix,:,:,0].squeeze())
ax2.set_title('Ground Truth')

#Function to add 2 convolutional layers with the parameters passed to it
def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):
    
    # first layer
    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)
    if batchnorm:ii
        x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    # second layer
    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    return x

#Function to add 3 convolutional layers with the parameters passed to it
def conv2d_block1(input_tensor, n_filters, kernel_size = 3, batchnorm = True):
    
    # first layer
    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    # second layer
    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation('relu')(x)

    # third layer
    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    return x

def get_vgg16(input_img, n_filters = 64, dropout = 0.1, batchnorm = True):
    """Function to define the VGG16 Model"""
    # Contracting Path
    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    p1 = MaxPooling2D((2, 2))(c1)
  
    
    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)
    p2 = MaxPooling2D((2, 2))(c2)
    
    
    c3 = conv2d_block1(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
    p3 = MaxPooling2D((2, 2))(c3)
    
    c4 = conv2d_block1(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    p4 = MaxPooling2D((2, 2))(c4)
    
    c5 = conv2d_block1(p4, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    p5 = MaxPooling2D((2, 2))(c5)
    
    # FCN converted to CNN
    c0 = Conv2D(6, (1,1), activation = 'relu')(p5)
    # Expansive Path
    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c0)
    u6 = concatenate([u6, c5])
    c6 = conv2d_block1(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    
    u7 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c6)
    u7 = concatenate([u7, c4])
    c7 = conv2d_block1(u7, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    
    u8 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c7)
    u8 = concatenate([u8, c3])
    c8 = conv2d_block1(u8, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
    
    u9 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c8)
    u9 = concatenate([u9, c2])
    c9 = conv2d_block(u9, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)

    u10 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c9)
    u10 = concatenate([u10, c1])
    c10 = conv2d_block(u10, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    
    outputs = Conv2D(6, (1, 1), activation='sigmoid')(c10)
    modelVGG = Model(inputs=[input_img], outputs=[outputs])
    return modelVGG



input_img = Input((im_height, im_width, 1), name='img')
modelVGG = get_vgg16(input_img, n_filters=32, dropout=0.05, batchnorm=True)
modelVGG.compile(optimizer=Adam(lr=0.001), loss="binary_crossentropy", metrics=["accuracy"])

modelVGG.summary()



#stop earlier even if epochs are not completed but purpose is served(VGG16)
callbacks = [
    EarlyStopping(patience=10, verbose=1),
    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1),
    ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/model-Pascal2012-VGG16E-50-H-.h5', verbose=1, save_best_only=True)
]

results = modelVGG.fit(X_train, y_train, batch_size=32, epochs=50, callbacks=callbacks,\
                    validation_data=(X_valid, y_valid))

#UNET
def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):
    """Function to define the UNET Model"""
    # Contracting Path
    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    p1 = MaxPooling2D((2, 2))(c1)
    p1 = Dropout(dropout)(p1)
    
    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)
    p2 = MaxPooling2D((2, 2))(c2)
    p2 = Dropout(dropout)(p2)
    
    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
    p3 = MaxPooling2D((2, 2))(c3)
    p3 = Dropout(dropout)(p3)
    
    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    p4 = MaxPooling2D((2, 2))(c4)
    p4 = Dropout(dropout)(p4)
    
    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)
    
    # Expansive Path
    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    
    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
    
    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)
    
    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)
    u9 = concatenate([u9, c1])
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    
    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)
    modelUNET = Model(inputs=[input_img], outputs=[outputs])
    return modelUNET


#print(keras.optimizers.Adam())
input_img1 = Input((im_height1, im_width1, 1), name='img1')
modelUNET = get_unet(input_img1, n_filters=16, dropout=0.05, batchnorm=True)
modelUNET.compile(optimizer=Adam(lr=0.001), loss="binary_crossentropy", metrics=["accuracy"])
modelUNET.summary()

#stop earlier even if epochs are not completed but purpose is served(UNET)
callbacks1 = [
    EarlyStopping(patience=10, verbose=1),
    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1),
    ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/model-Pascal-UNET-H-50.h5', verbose=1, save_best_only=True)
]

results1 = modelUNET.fit(X_train1, y_train1, batch_size=32, epochs=50, callbacks=callbacks1,\
                    validation_data=(X_valid1, y_valid1))

#plotting the learning curve(VGG16)
plt.figure(figsize=(8, 8))
plt.title("Learning curve-VGG")
plt.plot(results.history["loss"], label="loss")
plt.plot(results.history["val_loss"], label="val_loss")
plt.plot( np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")
plt.xlabel("Epochs")
plt.ylabel("log_loss")
plt.legend();

#plotting the learning curve(UNET)
plt.figure(figsize=(8, 8))
plt.title("Learning curve-UNET")
plt.plot(results1.history["loss"], label="loss")
plt.plot(results1.history["val_loss"], label="val_loss")
plt.plot( np.argmin(results1.history["val_loss"]), np.min(results1.history["val_loss"]), marker="x", color="r", label="best model")
plt.xlabel("Epochs")
plt.ylabel("log_loss")
plt.legend();

#LOADING TRAINED MODEL

#modelUNET = keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/model-tgs-salt-UNET.h5')

# LOADING TESTING DATA
ids = os.listdir('/content/gdrive/My Drive/Colab Notebooks/testing_images') # list of names all images in the given path
#print("No. of images = ", len(ids))

X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)

# tqdm is used to display the progress bar
for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):
    # Load images
    img = load_img("/content/gdrive/My Drive/Colab Notebooks/testing_images/"+id_, grayscale=True) #folder containing the testing data
    x_img = img_to_array(img)
    x_img1 = resize(x_img, (128, 128, 1), mode = 'constant', preserve_range = True
    # Save images
    X[n] = x_img/255.0
    #X1[n] = x_img1/255.0

# re-initialising arrays to avoid crashing
preds_train = []
preds_val = []
preds_train_t = []
preds_val_t = []

#(VGG16)
t = 0.2
# Predict on train, val and test
preds_train = modelVGG.predict(X_train, verbose=1)
preds_val = modelVGG.predict(X_valid, verbose=1)

# Threshold predictions
preds_train_t = (preds_train > t).astype(np.uint8)
preds_val_t = (preds_val > t).astype(np.uint8)

x = 13
z = 0
cv2_imshow(X_train[x,:,:,0]*255)
cv2_imshow(y_train[x,:,:,z]*255)
cv2_imshow(preds_train[x,:,:,z]*255)
cv2_imshow(preds_train_t[x,:,:,z]*255)

#UNET
p = 0.2
# Predict on train, val and test
preds_train1 = modelUNET.predict(X_train1, verbose=1)
preds_val1 = modelUNET.predict(X_valid1, verbose=1)

# Threshold predictions
preds_train_t1 = (preds_train1 > p).astype(np.uint8)
preds_val_t1 = (preds_val1 > p).astype(np.uint8)

def plot_sample(X, y, preds, binary_preds,s, ix=None):
    """Function to plot the results"""
    s = s
    if ix is None:
        ix = random.randint(0, len(X))
    print(ix)
    has_mask = y[ix].max() > 0

    fig, ax = plt.subplots(1, 4, figsize=(20, 10))
    ax[0].imshow(X[ix, ..., 0])
    #if has_mask:
    #    ax[0].contour(y[ix].squeeze(), colors='gray', levels=[0.5])
    ax[0].set_title('original image')

    ax[1].imshow(y[ix,:,:,s].squeeze())
    ax[1].set_title('ground truth')

    ax[2].imshow(preds[ix,:,:,s].squeeze(), vmin=0, vmax=1)
    #if has_mask:
    #    ax[2].contour(y[ix].squeeze(), colors='gray', levels=[0.5])
    ax[2].set_title(' Predicted')
    
    ax[3].imshow(binary_preds[ix,:,:,s].squeeze(), vmin=0, vmax=1)
    #if has_mask:
    #    ax[3].contour(y[ix].squeeze(), colors='gray', levels=[0.5])
    ax[3].set_title('Predicted binary');

#VGG16(TRAINING SET)
plot_sample(X_train, y_train, preds_train, preds_train_t,0,1712)

#UNET(TRAINING SET)
plot_sample(X_train1, y_train1, preds_train1, preds_train_t1)

#VGG16(VALIDATION SET)
plot_sample(X_valid, y_valid, preds_val, preds_val_t,1,209)

#UNET(VALIDATION SET)
plot_sample(X_valid1, y_valid1, preds_val1, preds_val_t1)
